{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "def solve_stackelberg_game(q_values_data):\n",
    "    # Convert q_values_data to matrix\n",
    "    num_defender_actions = max([entry['defender'] for entry in q_values_data]) + 1\n",
    "    num_attacker_actions = max([entry['attacker'] for entry in q_values_data]) + 1\n",
    "    Q_matrix = np.zeros((num_attacker_actions, num_defender_actions))\n",
    "    for entry in q_values_data:\n",
    "        Q_matrix[entry['attacker']][entry['defender']] = entry['q_value']\n",
    "    print(Q_matrix)\n",
    "    # Variables\n",
    "    q = cp.Variable(Q_matrix.shape[1], nonneg=True)  # Defender's strategy\n",
    "    z = cp.Variable()  # Worst-case expected payoff for defender\n",
    "\n",
    "    # Objective: Minimize z (worst-case expected payoff for defender)\n",
    "    objective = cp.Minimize(z)\n",
    "\n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        cp.sum(q) == 1,  # Defender's strategy should be a valid probability distribution\n",
    "        z >= np.min(Q_matrix)  # z should be greater than or equal to the minimum Q-value\n",
    "    ]\n",
    "    \n",
    "    # Expected payoff for each attacker action should be at least z\n",
    "    for i in range(num_attacker_actions):\n",
    "        constraints.append(Q_matrix[i] @ q <= z)\n",
    "\n",
    "    # Form and solve the problem\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve()\n",
    "\n",
    "    # Extract the optimal strategy for the defender\n",
    "    defender_strategy_cvxpy = q.value\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Defender's Optimal Strategy\": defender_strategy_cvxpy,\n",
    "        \"Minimum Expected Payoff for Defender\": prob.value\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# q_values_data = [\n",
    "#     {'defender': 0, 'attacker': 0, 'q_value': 2.875578551458811},\n",
    "#     {'defender': 0, 'attacker': 1, 'q_value': 3.056369607957987},\n",
    "#     {'defender': 0, 'attacker': 2, 'q_value': 4.0227094368930505},\n",
    "#     {'defender': 1, 'attacker': 0, 'q_value': 2.8071575865839846},\n",
    "#     {'defender': 1, 'attacker': 1, 'q_value': 3.1118154849842843},\n",
    "#     {'defender': 1, 'attacker': 2, 'q_value': 4.59990844267451},\n",
    "#     {'defender': 2, 'attacker': 0, 'q_value': 2.884321680025897},\n",
    "#     {'defender': 2, 'attacker': 1, 'q_value': 3.586291563285632},\n",
    "#     {'defender': 2, 'attacker': 2, 'q_value': 4.1127920519612555}\n",
    "# ]\n",
    "\n",
    "q_values_data = [{'defender': 0, 'attacker': 0, 'q_value': -3.8756854565446464}, \n",
    "                 {'defender': 0, 'attacker': 1, 'q_value': -2.265702286453962}, \n",
    "                 {'defender': 0, 'attacker': 2, 'q_value': -3.467078694389465}, \n",
    "                 {'defender': 1, 'attacker': 0, 'q_value': -4.25523030477664}, \n",
    "                 {'defender': 1, 'attacker': 1, 'q_value': -3.444391083127282}, \n",
    "                 {'defender': 1, 'attacker': 2, 'q_value': -3.1855277873757535}, \n",
    "                 {'defender': 2, 'attacker': 0, 'q_value': -4.23960687623448}, \n",
    "                 {'defender': 2, 'attacker': 1, 'q_value': -2.063042116749623}, \n",
    "                 {'defender': 2, 'attacker': 2, 'q_value': -3.5771692712357543}]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = solve_stackelberg_game(q_values_data)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "# Payoff matrix\n",
    "payoff_matrix = jnp.array([\n",
    "    [-3.87568546, -4.2552303,  -4.23960688],\n",
    "    [-2.26570229, -3.44439108, -2.06304212],\n",
    "    [-3.46707869, -3.18552779, -3.57716927]\n",
    "])\n",
    "\n",
    "# Distance squared between two players (still unused in the current context)\n",
    "distance_squared = jnp.sum((jnp.array([0.0, 0.0]) - jnp.array([2.0, 2.0]))**2)\n",
    "\n",
    "# Define the Lagrangian for the inner loop\n",
    "def lagrangian_inner(strategy_defender, strategy_attacker, lam):\n",
    "    expected_payoff = jnp.dot(jnp.dot(strategy_defender, payoff_matrix), strategy_attacker)\n",
    "    constraint = distance_squared - 0.5**2\n",
    "    return expected_payoff - lam * constraint\n",
    "\n",
    "# Gradient computations\n",
    "grad_lagrangian_defender = jax.jit(jax.grad(lagrangian_inner, argnums=0))\n",
    "grad_lagrangian_attacker = jax.jit(jax.grad(lagrangian_inner, argnums=1))\n",
    "grad_lagrangian_lambda = jax.jit(jax.grad(lagrangian_inner, argnums=2))\n",
    "\n",
    "# Optimizers\n",
    "optimizer_defender = optax.sgd(0.001)\n",
    "optimizer_attacker = optax.sgd(0.001)\n",
    "optimizer_lambda = optax.sgd(0.001)\n",
    "\n",
    "def nested_optimization(initial_strategy_defender, initial_strategy_attacker, initial_lambda):\n",
    "    params = {\n",
    "        'strategy_defender': initial_strategy_defender,\n",
    "        'strategy_attacker': initial_strategy_attacker,\n",
    "        'lambda': initial_lambda\n",
    "    }\n",
    "\n",
    "    opt_state_defender = optimizer_defender.init(params)\n",
    "    opt_state_attacker = optimizer_attacker.init(params)\n",
    "    opt_state_lambda = optimizer_lambda.init(params)\n",
    "    \n",
    "    # Outer loop for defender optimization\n",
    "    for _ in range(100):\n",
    "        \n",
    "        # Inner loop for attacker response\n",
    "        for _ in range(100):\n",
    "            grad_defender = -1*grad_lagrangian_defender(params['strategy_defender'], params['strategy_attacker'], params['lambda'])\n",
    "            grad_attacker = grad_lagrangian_attacker(params['strategy_defender'], params['strategy_attacker'], params['lambda'])\n",
    "            grad_lambda = -1*grad_lagrangian_lambda(params['strategy_defender'], params['strategy_attacker'], params['lambda'])\n",
    "            \n",
    "            # Update attacker strategy\n",
    "            updates, opt_state_attacker = optimizer_attacker.update({'strategy_attacker': grad_attacker}, opt_state_attacker)\n",
    "            updates['strategy_defender'] = jnp.zeros_like(params['strategy_defender'])\n",
    "            updates['lambda'] = jnp.zeros_like(params['lambda'])\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            \n",
    "            # Update lambda\n",
    "            updates, opt_state_lambda = optimizer_lambda.update({'lambda': grad_lambda}, opt_state_lambda)\n",
    "            updates['strategy_defender'] = jnp.zeros_like(params['strategy_defender'])\n",
    "            updates['strategy_attacker'] = jnp.zeros_like(params['strategy_attacker'])\n",
    "            params = optax.apply_updates(params, updates)\n",
    "\n",
    "            # Ensure lambda remains non-negative\n",
    "            params['lambda'] = jnp.maximum(0, params['lambda'])\n",
    "            \n",
    "            # Normalize attacker strategy to be a valid probability distribution\n",
    "            params['strategy_attacker'] /= jnp.sum(params['strategy_attacker'])\n",
    "        \n",
    "        # Update defender strategy based on attacker's response\n",
    "        updates, opt_state_defender = optimizer_defender.update({'strategy_defender': grad_defender}, opt_state_defender)\n",
    "        updates['strategy_attacker'] = jnp.zeros_like(params['strategy_attacker'])\n",
    "        updates['lambda'] = jnp.zeros_like(params['lambda'])\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        # Normalize defender strategy to be a valid probability distribution\n",
    "        params['strategy_defender'] /= jnp.sum(params['strategy_defender'])\n",
    "\n",
    "    return params['strategy_defender'], params['strategy_attacker']\n",
    "\n",
    "# Test the nested optimization\n",
    "initial_strategy_defender = jnp.array([1/3, 1/3, 1/3])\n",
    "initial_strategy_attacker = jnp.array([1/3, 1/3, 1/3])\n",
    "initial_lambda = jnp.array(1.0)\n",
    "optimized_strategy_defender, optimized_strategy_attacker = nested_optimization(initial_strategy_defender, initial_strategy_attacker, initial_lambda)\n",
    "\n",
    "def compute_expected_payoff(strategy_defender, strategy_attacker):\n",
    "    return jnp.dot(jnp.dot(strategy_defender, payoff_matrix), strategy_attacker)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Optimized Strategy (Defender):\", optimized_strategy_defender)\n",
    "print(\"Optimized Strategy (Attacker):\", optimized_strategy_attacker)\n",
    "\n",
    "compute_expected_payoff(optimized_strategy_defender, optimized_strategy_attacker)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
